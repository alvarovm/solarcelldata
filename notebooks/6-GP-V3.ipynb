{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to HPC: Solar Cell project\n",
    "\n",
    "Project: Solar Power for Affordable Housing through Computational Design of Low-Cost/High-Efficiency Solar Cells.\n",
    "Author: AlvaroVM [https://alvarovm.github.io](http://alvarovm.github.io)\n",
    "\n",
    "Version: 0.0.2\n",
    "\n",
    "## Part 6 Machine Learning with Gaussian Process Regression \n",
    "\n",
    "In this notebook we will use Gaussian Process Regression (GPR) to predict molecular optical activity, particularly to predict the spectral peak that corresponds to the first excitation energy. In this exercise we will need to the DyeDB and the data we agregated in previous notebooks.\n",
    "\n",
    "We would use GPR algorithm implemented in the GPflow code. This implementation relies on Tensorflow, which is a popular package for artificial intelligence and is portable among different computer architectures. Tensorflow could use GPUs and accelerate regression and inference. One advantage of fast regression is that we could optimize hyper parameters and create models that fit better the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs \n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.rdMolDescriptors import  GetHashedMorganFingerprint\n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "print(f'        RDkit version : {rdkit.__version__}')\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# utils\n",
    "from collections import OrderedDict\n",
    "from tqdm.autonotebook import tqdm\n",
    "# scientific python\n",
    "\n",
    "#import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.ensemble\n",
    "import scipy.stats\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'   Tensorflow version : {tf.__version__}')\n",
    "print(\"{} GPU(s) recognized by tensorflow:\".format(len(tf.config.list_physical_devices('GPU'))), tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary\n",
    "print(f'       GPflow version : {gpflow.__version__}')\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell gives us a couple options for debugging Tensorflow.\n",
    "# It is the first code cell, because it must be run, before the TensorFlow library is imported and it is most convenient to import all modules in the next cell\n",
    "# To enable this debugging, you must change one of the debugging flags to True and run this cell *before* importing running later cells\n",
    "# Currently this is only done manually from the notebook, but could be included as a JSON setting in the future if desirable\n",
    "\n",
    "# import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "#export CUDA_VISIBLE_DEVICE=\n",
    "#export CUDA_VISIBLE_DEVICE=0\n",
    "#export CUDA_VISIBLE_DEVICE=0,1\n",
    "\n",
    "# Disable GPUS\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# print(f'   Tensorflow version : {tf.__version__}')\n",
    "# print(\"{} GPU(s) recognized by tensorflow:\".format(len(tf.config.list_physical_devices('GPU'))), tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, target):\n",
    "    \"\"\"\n",
    "    Input Args:\n",
    "    pred: predictions numpy array\n",
    "    target :True label numpy array\n",
    "    return : rmse \n",
    "    \"\"\"\n",
    "    return np.sqrt(((pred - target) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles as smi2mol\n",
    "from rdkit.Chem.rdMolDescriptors import  GetHashedMorganFingerprint,GetMorganFingerprintAsBitVect\n",
    "\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles as smi2mol\n",
    "def canon_smiles(smi):\n",
    "    try:\n",
    "        m = smi2mol(smi)\n",
    "        if m is None:\n",
    "            #print('hola'+smi)\n",
    "            return False\n",
    "        else:\n",
    "            return Chem.MolToSmiles(m, isomericSmiles=True, canonical=True)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def applyMorganFP(m,**kwargs):\n",
    "    fptype='bit'\n",
    "    \n",
    "    if 'fptype' in kwargs:\n",
    "        fptype=kwargs['fptype']\n",
    "    if 'fp_args' in kwargs:\n",
    "        fp_args=kwargs['fp_args']     \n",
    "    #fp_args = self.meta_data['fp_args']\n",
    "    #fptype = self.meta_data['fptype']\n",
    "    arr = np.zeros((1,))\n",
    "    if fptype == 'bit': \n",
    "        arr = np.zeros((1,))\n",
    "        #ConvertToNumpyArray(GetHashedMorganFingerprint(m, **fp_args), arr)\n",
    "        try:\n",
    "            arr = np.array(GetMorganFingerprintAsBitVect(m, **fp_args))\n",
    "        except:\n",
    "            print(Chem.MolToSmiles(m))\n",
    "    elif fptype == 'count':\n",
    "        #arr = np.zeros((1,))\n",
    "        ConvertToNumpyArray(GetHashedMorganFingerprint(m, **fp_args), arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/../data/extended_db_Zindo_Nov_2019_V5_cannfp_clust_lem.pkl').fillna(value = 0)\n",
    "print('Column names: {}'.format(str(df.columns.tolist())))\n",
    "print('Table Shape: {}'.format(df.shape))\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[df['lambda_tddft (nm)']>0]\n",
    "df=df[df['lambda_sTDA (nm)']>0]\n",
    "#df=df[df['cluster']>-1]\n",
    "print('Table Shape: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample randomly a faction of the data and reset indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=1000, replace=True, random_state=1)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getonly=['NHOHCount', 'NOCount', 'NumAliphaticCarbocycles',\n",
    "                           'NumAliphaticHeterocycles', 'NumAliphaticRings',\n",
    "                           'NumAromaticCarbocycles', 'NumAromaticHeterocycles',\n",
    "                           'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', \n",
    "                           'NumHeteroatoms', 'NumRadicalElectrons', 'NumRotatableBonds',\n",
    "                           'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', \n",
    "                           'NumSaturatedRings', 'NumValenceElectrons',\n",
    "'qed','TPSA', 'MolLogP', 'MolMR','BalabanJ', 'BertzCT',\n",
    "'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO',\n",
    "                            'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', \n",
    "                            'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine',\n",
    "                            'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1',\n",
    "                            'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde',\n",
    "                            'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide',\n",
    "                            'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo',\n",
    "                            'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic',\n",
    "                            'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether',\n",
    "                            'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', \n",
    "                            'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone',\n",
    "                            'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine',\n",
    "                            'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', \n",
    "                            'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', \n",
    "                            'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', \n",
    "                            'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd',\n",
    "                            'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone',\n",
    "                            'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', \n",
    "                            'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea',\n",
    "                            'MolWt','MolLogP']\n",
    "getonly=['NHOHCount', 'NOCount', 'NumAliphaticCarbocycles',\n",
    "                           'NumAliphaticHeterocycles', 'NumAliphaticRings',\n",
    "                           'NumAromaticCarbocycles', 'NumAromaticHeterocycles',\n",
    "                           'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', \n",
    "                           'NumHeteroatoms', 'NumRadicalElectrons', 'NumRotatableBonds',\n",
    "                           'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', \n",
    "                           'NumSaturatedRings', 'NumValenceElectrons',\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import rdkit.Chem.Descriptors as Descriptors\n",
    "\n",
    "\n",
    "# calc_props = OrderedDict(inspect.getmembers(Descriptors, inspect.isfunction))\n",
    "# for key in list(calc_props.keys()):\n",
    "#     if key.startswith('_'):\n",
    "#         del calc_props[key]\n",
    "#     else:\n",
    "#         thisnot=False\n",
    "#         for myprop in getonly:\n",
    "#             if myprop == key:\n",
    "#                 thisnot=True\n",
    "#         if not thisnot:\n",
    "#             del calc_props[key]\n",
    "\n",
    "\n",
    "# def calc_all(df,calc_props,smiles_col='smiles'):\n",
    "#     df['mol'] = df[smiles_col].apply(Chem.MolFromSmiles)\n",
    "#     for key,val in calc_props.items():\n",
    "#         df[key] = df['mol'].apply(val)\n",
    "#         #df[key] = df['mol'].swifter.apply(val)\n",
    "#     return df\n",
    "# print('Found {} molecular descriptors in RDKIT'.format(len(calc_props)))\n",
    "# #calc_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gpmol.features.fingerprint_features import canon_smiles\n",
    "#from gpmol.features.fingerprints3D_features import geo3d_sanity_check\n",
    "#from gpmol.utils.mol import canon_smiles\n",
    "\n",
    "\n",
    "\n",
    "print('Before properties: {}'.format(str(df.columns.tolist())))\n",
    "#df = geo3d_sanity_check(df)\n",
    "#df['smiles'] = df['smi'].apply(canon_smiles)\n",
    "#df['smiles'] = df['SMI']\n",
    "#calc_all(df,calc_props)\n",
    "#df['mol'] = df['smiles'].apply(Chem.MolFromSmiles)\n",
    "#df['morganfps']=df['mol'].apply(applyMorganFP,fp_args={'radius':4, 'nBits':2048})\n",
    "#print(df.shape)\n",
    "#df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc_all(df,calc_props)\n",
    "#print('After properties: {}'.format(str(df.columns.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_mask(x, y, k):\n",
    "   rf = sklearn.ensemble.RandomForestRegressor()\n",
    "   rf.fit(x,y)\n",
    "   indices = (-rf.feature_importances_).argsort()[:k]\n",
    "   mask = np.zeros_like(rf.feature_importances_)\n",
    "   mask[indices] = 1.0\n",
    "   return mask.astype(bool)\n",
    "\n",
    "class IdentityTransformer(sklearn.preprocessing.FunctionTransformer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(lambda x:x, lambda x:x)\n",
    "\n",
    "class GPFeature():\n",
    "    \n",
    "    def __init__(self, label, x, y, n_features=None, preproc=None):\n",
    "        self.label = label\n",
    "        n_features = n_features or x.shape[-1]\n",
    "        x_feats = x.shape[-1]\n",
    "        if n_features > x_feats:\n",
    "            raise ValueError(f'n_features={n_features} larger than x.shape[-1] {x_feats}')\n",
    "        elif n_features < x_feats:\n",
    "            mask = rf_feature_mask(x, y, n_features)\n",
    "        else:\n",
    "            mask = np.ones(x_feats).astype(bool)\n",
    "        self.mask = mask\n",
    "        preproc = preproc or IdentityTransformer()\n",
    "        self.preproc = preproc.fit(x[:,self.mask])\n",
    "        self.ndim = sum(self.mask)\n",
    "        self.active_dims = np.arange(self.ndim)\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return self.preproc.transform(x[:,self.mask]).astype(np.float64)\n",
    "    \n",
    "def evaluate_result(y_true, y_pred, fold=None):\n",
    "    result = OrderedDict()\n",
    "    result['r2'] = sklearn.metrics.r2_score(y_true,y_pred)\n",
    "    result['rmse'] = np.sqrt(sklearn.metrics.mean_squared_error(y_true,y_pred))\n",
    "    result['mae'] = np.sqrt(sklearn.metrics.mean_absolute_error(y_true,y_pred))\n",
    "    result['r'] = scipy.stats.pearsonr(y_test.ravel(),y_pred.ravel())[0]\n",
    "    if fold:\n",
    "        result['cv'] = fold\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=df.index.tolist()\n",
    "train_index,test_index = sklearn.model_selection.train_test_split(indices, test_size=.30)\n",
    "print(len(train_index),len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='lambda_sTDA (nm)'\n",
    "y_true = df[target].values.reshape(-1,1).astype(np.float64)\n",
    "y_preproc = sklearn.preprocessing.StandardScaler()\n",
    "y_train = y_preproc.fit_transform(y_true[train_index])\n",
    "y_test = y_true[test_index]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select fingerprint and select the most relevant features that will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fp = np.vstack(df['morganfps-b'])\n",
    "print(fp.shape)\n",
    "#n_features = 200\n",
    "fp_feat = GPFeature('fp', fp[train_index], y_train, 200)\n",
    "fp_train = fp_feat.transform(fp[train_index]) \n",
    "fp_test = fp_feat.transform(fp[test_index]) \n",
    "print(fp_train.shape,fp_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = getonly\n",
    "x_tmp = df[other_features].values\n",
    "#n_features = 4\n",
    "chem_feat = GPFeature('chemoinformatic', x_tmp[train_index],y_train, 4, sklearn.preprocessing.StandardScaler())\n",
    "chem_train = chem_feat.transform(x_tmp[train_index])\n",
    "chem_test = chem_feat.transform(x_tmp[test_index])\n",
    "print(chem_train.shape,chem_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine fingerprint and descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.hstack((fp_train,chem_train))\n",
    "x_test = np.hstack((fp_test,chem_test))\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_dim = 0\n",
    "fp_kernel = gpflow.kernels.RBF(active_dims=fp_feat.active_dims+last_dim)\n",
    "last_dim  = fp_kernel.active_dims[-1]+1\n",
    "chem_kernel = gpflow.kernels.RBF(active_dims=chem_feat.active_dims+last_dim)\n",
    "kernel = fp_kernel + chem_kernel\n",
    "print_summary(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpflow.models.GPR(data=(x_train, y_train), kernel=kernel, mean_function=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = gpflow.optimizers.Scipy()\n",
    "\n",
    "def objective():\n",
    "    return - model.log_marginal_likelihood()\n",
    "\n",
    "opt_logs = opt.minimize(objective,\n",
    "                        model.trainable_variables,\n",
    "                        options=dict(maxiter=500))\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict and scale (inverse), print statistics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred, y_std  = model.predict_y(x_test)\n",
    "y_pred = y_preproc.inverse_transform(y_pred.numpy())\n",
    "results = [evaluate_result(y_test, y_pred)]\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the comparison between predicted and true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Y Pred')\n",
    "plt.title(f\"GPR {target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr",
   "language": "python",
   "name": "gpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
